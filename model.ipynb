{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "%matplotlib inline\n",
    "import tensorflow.python.keras.engine.base_layer_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('BTC-Hourly.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unix</th>\n",
       "      <th>date</th>\n",
       "      <th>symbol</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>Volume BTC</th>\n",
       "      <th>Volume USD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1646092800</td>\n",
       "      <td>2022-03-01 00:00:00</td>\n",
       "      <td>BTC/USD</td>\n",
       "      <td>43221.71</td>\n",
       "      <td>43626.49</td>\n",
       "      <td>43185.48</td>\n",
       "      <td>43312.27</td>\n",
       "      <td>52.056320</td>\n",
       "      <td>2.254677e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1646089200</td>\n",
       "      <td>2022-02-28 23:00:00</td>\n",
       "      <td>BTC/USD</td>\n",
       "      <td>43085.30</td>\n",
       "      <td>43364.81</td>\n",
       "      <td>42892.37</td>\n",
       "      <td>43178.98</td>\n",
       "      <td>106.816103</td>\n",
       "      <td>4.612210e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1646085600</td>\n",
       "      <td>2022-02-28 22:00:00</td>\n",
       "      <td>BTC/USD</td>\n",
       "      <td>41657.23</td>\n",
       "      <td>44256.08</td>\n",
       "      <td>41650.29</td>\n",
       "      <td>42907.32</td>\n",
       "      <td>527.540571</td>\n",
       "      <td>2.263535e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1646082000</td>\n",
       "      <td>2022-02-28 21:00:00</td>\n",
       "      <td>BTC/USD</td>\n",
       "      <td>41917.09</td>\n",
       "      <td>41917.09</td>\n",
       "      <td>41542.60</td>\n",
       "      <td>41659.53</td>\n",
       "      <td>69.751680</td>\n",
       "      <td>2.905822e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1646078400</td>\n",
       "      <td>2022-02-28 20:00:00</td>\n",
       "      <td>BTC/USD</td>\n",
       "      <td>41361.99</td>\n",
       "      <td>41971.00</td>\n",
       "      <td>41284.11</td>\n",
       "      <td>41914.97</td>\n",
       "      <td>247.151654</td>\n",
       "      <td>1.035935e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         unix                 date   symbol      open      high       low  \\\n",
       "0  1646092800  2022-03-01 00:00:00  BTC/USD  43221.71  43626.49  43185.48   \n",
       "1  1646089200  2022-02-28 23:00:00  BTC/USD  43085.30  43364.81  42892.37   \n",
       "2  1646085600  2022-02-28 22:00:00  BTC/USD  41657.23  44256.08  41650.29   \n",
       "3  1646082000  2022-02-28 21:00:00  BTC/USD  41917.09  41917.09  41542.60   \n",
       "4  1646078400  2022-02-28 20:00:00  BTC/USD  41361.99  41971.00  41284.11   \n",
       "\n",
       "      close  Volume BTC    Volume USD  \n",
       "0  43312.27   52.056320  2.254677e+06  \n",
       "1  43178.98  106.816103  4.612210e+06  \n",
       "2  42907.32  527.540571  2.263535e+07  \n",
       "3  41659.53   69.751680  2.905822e+06  \n",
       "4  41914.97  247.151654  1.035935e+07  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 33259 entries, 0 to 33258\n",
      "Data columns (total 9 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   unix        33259 non-null  int64  \n",
      " 1   date        33259 non-null  object \n",
      " 2   symbol      33259 non-null  object \n",
      " 3   open        33259 non-null  float64\n",
      " 4   high        33259 non-null  float64\n",
      " 5   low         33259 non-null  float64\n",
      " 6   close       33259 non-null  float64\n",
      " 7   Volume BTC  33259 non-null  float64\n",
      " 8   Volume USD  33259 non-null  float64\n",
      "dtypes: float64(6), int64(1), object(2)\n",
      "memory usage: 2.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unix          0\n",
       "date          0\n",
       "symbol        0\n",
       "open          0\n",
       "high          0\n",
       "low           0\n",
       "close         0\n",
       "Volume BTC    0\n",
       "Volume USD    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"date\"]=pd.to_datetime(df[\"date\"])\n",
    "df[\"day\"]=(df[\"date\"]).dt.day\n",
    "df[\"month\"]=(df[\"date\"]).dt.month\n",
    "df[\"year\"]=(df[\"date\"]).dt.year\n",
    "df[\"time\"]=(df[\"date\"]).dt.time\n",
    "del df[\"date\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['time']=df['time'].astype(str) #We change the type of time to string.\n",
    "df[\"time\"]=df.time.str.replace(':00','') #We delete the minute part of time.\n",
    "df['day']=df['day'].astype(int)\n",
    "df['month']=df['month'].astype(int)\n",
    "df['year']=df['year'].astype(int)\n",
    "df['time']=df['time'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unix</th>\n",
       "      <th>symbol</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>Volume BTC</th>\n",
       "      <th>Volume USD</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1646092800</td>\n",
       "      <td>BTC/USD</td>\n",
       "      <td>43221.71</td>\n",
       "      <td>43626.49</td>\n",
       "      <td>43185.48</td>\n",
       "      <td>43312.27</td>\n",
       "      <td>52.056320</td>\n",
       "      <td>2.254677e+06</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2022</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1646089200</td>\n",
       "      <td>BTC/USD</td>\n",
       "      <td>43085.30</td>\n",
       "      <td>43364.81</td>\n",
       "      <td>42892.37</td>\n",
       "      <td>43178.98</td>\n",
       "      <td>106.816103</td>\n",
       "      <td>4.612210e+06</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>2022</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1646085600</td>\n",
       "      <td>BTC/USD</td>\n",
       "      <td>41657.23</td>\n",
       "      <td>44256.08</td>\n",
       "      <td>41650.29</td>\n",
       "      <td>42907.32</td>\n",
       "      <td>527.540571</td>\n",
       "      <td>2.263535e+07</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>2022</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1646082000</td>\n",
       "      <td>BTC/USD</td>\n",
       "      <td>41917.09</td>\n",
       "      <td>41917.09</td>\n",
       "      <td>41542.60</td>\n",
       "      <td>41659.53</td>\n",
       "      <td>69.751680</td>\n",
       "      <td>2.905822e+06</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>2022</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1646078400</td>\n",
       "      <td>BTC/USD</td>\n",
       "      <td>41361.99</td>\n",
       "      <td>41971.00</td>\n",
       "      <td>41284.11</td>\n",
       "      <td>41914.97</td>\n",
       "      <td>247.151654</td>\n",
       "      <td>1.035935e+07</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>2022</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         unix   symbol      open      high       low     close  Volume BTC  \\\n",
       "0  1646092800  BTC/USD  43221.71  43626.49  43185.48  43312.27   52.056320   \n",
       "1  1646089200  BTC/USD  43085.30  43364.81  42892.37  43178.98  106.816103   \n",
       "2  1646085600  BTC/USD  41657.23  44256.08  41650.29  42907.32  527.540571   \n",
       "3  1646082000  BTC/USD  41917.09  41917.09  41542.60  41659.53   69.751680   \n",
       "4  1646078400  BTC/USD  41361.99  41971.00  41284.11  41914.97  247.151654   \n",
       "\n",
       "     Volume USD  day  month  year  time  \n",
       "0  2.254677e+06    1      3  2022     0  \n",
       "1  4.612210e+06   28      2  2022    23  \n",
       "2  2.263535e+07   28      2  2022    22  \n",
       "3  2.905822e+06   28      2  2022    21  \n",
       "4  1.035935e+07   28      2  2022    20  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "high          1.000000\n",
       "open          0.999958\n",
       "close         0.999958\n",
       "low           0.999905\n",
       "unix          0.824581\n",
       "year          0.801393\n",
       "Volume USD    0.482761\n",
       "time          0.000503\n",
       "day           0.012292\n",
       "month         0.039328\n",
       "Volume BTC    0.324982\n",
       "Name: high, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(df.drop('symbol',axis=1).corr()[\"high\"].sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler=MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33259, 7)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y=df.drop([\"low\",\"close\",\"open\",\"high\",\"symbol\"],axis=1),df[[\"high\"]]\n",
    "x=scaler.fit_transform(x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.20,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(84,activation=\"relu\"))\n",
    "model.add(Dense(84,activation=\"relu\"))\n",
    "model.add(Dense(84,activation=\"relu\"))\n",
    "model.add(Dense(84,activation=\"relu\"))\n",
    "model.add(Dense(84,activation=\"relu\"))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer=\"adam\",loss=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "208/208 [==============================] - 3s 5ms/step - loss: 416577120.0000 - val_loss: 146949968.0000\n",
      "Epoch 2/100\n",
      "208/208 [==============================] - 1s 4ms/step - loss: 92244296.0000 - val_loss: 67721544.0000\n",
      "Epoch 3/100\n",
      "208/208 [==============================] - 1s 4ms/step - loss: 57846252.0000 - val_loss: 51398920.0000\n",
      "Epoch 4/100\n",
      "208/208 [==============================] - 1s 4ms/step - loss: 50016616.0000 - val_loss: 47327584.0000\n",
      "Epoch 5/100\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 46612956.0000 - val_loss: 43948272.0000\n",
      "Epoch 6/100\n",
      "208/208 [==============================] - 1s 4ms/step - loss: 43129836.0000 - val_loss: 40441404.0000\n",
      "Epoch 7/100\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 39799988.0000 - val_loss: 37956872.0000\n",
      "Epoch 8/100\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 37032292.0000 - val_loss: 35365132.0000\n",
      "Epoch 9/100\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 34609396.0000 - val_loss: 33026354.0000\n",
      "Epoch 10/100\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 32378186.0000 - val_loss: 31698372.0000\n",
      "Epoch 11/100\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 30685400.0000 - val_loss: 29470648.0000\n",
      "Epoch 12/100\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 28887030.0000 - val_loss: 27272592.0000\n",
      "Epoch 13/100\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 26637052.0000 - val_loss: 28477970.0000\n",
      "Epoch 14/100\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 25173218.0000 - val_loss: 24703018.0000\n",
      "Epoch 15/100\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 24245764.0000 - val_loss: 23305142.0000\n",
      "Epoch 16/100\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 22907616.0000 - val_loss: 23112364.0000\n",
      "Epoch 17/100\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 21815954.0000 - val_loss: 22522206.0000\n",
      "Epoch 18/100\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 20455876.0000 - val_loss: 19026866.0000\n",
      "Epoch 19/100\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 18607606.0000 - val_loss: 17448004.0000\n",
      "Epoch 20/100\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 16516810.0000 - val_loss: 15985757.0000\n",
      "Epoch 21/100\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 14949978.0000 - val_loss: 14478633.0000\n",
      "Epoch 22/100\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 13557278.0000 - val_loss: 12900926.0000\n",
      "Epoch 23/100\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 12647284.0000 - val_loss: 12751128.0000\n",
      "Epoch 24/100\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 11791155.0000 - val_loss: 10970934.0000\n",
      "Epoch 25/100\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 11320734.0000 - val_loss: 10555442.0000\n",
      "Epoch 26/100\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 10958813.0000 - val_loss: 10321483.0000\n",
      "Epoch 27/100\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 10600870.0000 - val_loss: 10512708.0000\n",
      "Epoch 28/100\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 10477179.0000 - val_loss: 10247523.0000\n",
      "Epoch 29/100\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 9909601.0000 - val_loss: 9580505.0000\n",
      "Epoch 30/100\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 10135773.0000 - val_loss: 11289028.0000\n",
      "Epoch 31/100\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 9783422.0000 - val_loss: 10630955.0000\n",
      "Epoch 32/100\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 9606894.0000 - val_loss: 9393937.0000\n",
      "Epoch 33/100\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 9793710.0000 - val_loss: 9275838.0000\n",
      "Epoch 34/100\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 9539997.0000 - val_loss: 8716724.0000\n",
      "Epoch 35/100\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 9471430.0000 - val_loss: 8822899.0000\n",
      "Epoch 36/100\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 9017733.0000 - val_loss: 8688519.0000\n",
      "Epoch 37/100\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 8794737.0000 - val_loss: 8594225.0000\n",
      "Epoch 38/100\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 8660793.0000 - val_loss: 8857918.0000\n",
      "Epoch 39/100\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 8813426.0000 - val_loss: 8808704.0000\n",
      "Epoch 40/100\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 8650738.0000 - val_loss: 8431276.0000\n",
      "Epoch 41/100\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 8886734.0000 - val_loss: 9113561.0000\n",
      "Epoch 42/100\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 8539453.0000 - val_loss: 8186787.5000\n",
      "Epoch 43/100\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 8505544.0000 - val_loss: 8031567.0000\n",
      "Epoch 44/100\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 8212716.5000 - val_loss: 8037903.0000\n",
      "Epoch 45/100\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 8403329.0000 - val_loss: 8126113.5000\n",
      "Epoch 46/100\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 8296213.5000 - val_loss: 8372436.0000\n",
      "Epoch 47/100\n",
      "208/208 [==============================] - 1s 4ms/step - loss: 8454693.0000 - val_loss: 7693299.0000\n",
      "Epoch 48/100\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 8349359.0000 - val_loss: 7978712.5000\n",
      "Epoch 49/100\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 8085669.5000 - val_loss: 7918526.0000\n",
      "Epoch 50/100\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 8057458.0000 - val_loss: 7802562.5000\n",
      "Epoch 51/100\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 7821673.5000 - val_loss: 7698735.5000\n",
      "Epoch 52/100\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 7633774.0000 - val_loss: 7472490.0000\n",
      "Epoch 53/100\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 7660865.0000 - val_loss: 7387922.5000\n",
      "Epoch 54/100\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 7534810.0000 - val_loss: 7822595.0000\n",
      "Epoch 55/100\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 7756225.0000 - val_loss: 7196531.5000\n",
      "Epoch 56/100\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 7354164.0000 - val_loss: 7246944.0000\n",
      "Epoch 57/100\n",
      "208/208 [==============================] - 1s 2ms/step - loss: 7289949.5000 - val_loss: 6781247.5000\n",
      "Epoch 58/100\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 7085773.5000 - val_loss: 7524115.5000\n",
      "Epoch 59/100\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 7101431.5000 - val_loss: 6853494.0000\n",
      "Epoch 60/100\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 6991785.0000 - val_loss: 6564202.0000\n",
      "Epoch 61/100\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 6783547.5000 - val_loss: 7768447.0000\n",
      "Epoch 62/100\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 6764837.5000 - val_loss: 6373530.5000\n",
      "Epoch 63/100\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 6626508.5000 - val_loss: 7293104.0000\n",
      "Epoch 64/100\n",
      "208/208 [==============================] - 1s 2ms/step - loss: 6906291.5000 - val_loss: 8818058.0000\n",
      "Epoch 65/100\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 6486294.5000 - val_loss: 6103489.5000\n",
      "Epoch 66/100\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 6282295.5000 - val_loss: 6112279.0000\n",
      "Epoch 67/100\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 6158804.0000 - val_loss: 5681483.5000\n",
      "Epoch 68/100\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 5983287.5000 - val_loss: 6438429.0000\n",
      "Epoch 69/100\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 5866308.0000 - val_loss: 5568733.0000\n",
      "Epoch 70/100\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 5705545.5000 - val_loss: 6252387.5000\n",
      "Epoch 71/100\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 5635234.0000 - val_loss: 7351118.0000\n",
      "Epoch 72/100\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 5565752.0000 - val_loss: 5250787.0000\n",
      "Epoch 73/100\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 5435225.5000 - val_loss: 4990427.5000\n",
      "Epoch 74/100\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 5489552.5000 - val_loss: 5113156.0000\n",
      "Epoch 75/100\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 4930432.0000 - val_loss: 4920870.5000\n",
      "Epoch 76/100\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 5087170.5000 - val_loss: 10873209.0000\n",
      "Epoch 77/100\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 4918454.0000 - val_loss: 4531306.0000\n",
      "Epoch 78/100\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 4751256.0000 - val_loss: 5440408.5000\n",
      "Epoch 79/100\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 4506508.0000 - val_loss: 4705532.5000\n",
      "Epoch 80/100\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 4577690.5000 - val_loss: 4409204.0000\n",
      "Epoch 81/100\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 4626732.0000 - val_loss: 4954835.5000\n",
      "Epoch 82/100\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 4411894.5000 - val_loss: 4000971.2500\n",
      "Epoch 83/100\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 4175445.7500 - val_loss: 4000902.0000\n",
      "Epoch 84/100\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 4823580.0000 - val_loss: 4463095.5000\n",
      "Epoch 85/100\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 4177630.5000 - val_loss: 3921555.2500\n",
      "Epoch 86/100\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 3950504.2500 - val_loss: 5862059.0000\n",
      "Epoch 87/100\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 4148598.2500 - val_loss: 5094012.0000\n",
      "Epoch 88/100\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 4100136.2500 - val_loss: 3658842.0000\n",
      "Epoch 89/100\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 3953298.5000 - val_loss: 3672826.5000\n",
      "Epoch 90/100\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 3814541.7500 - val_loss: 3585146.2500\n",
      "Epoch 91/100\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 3807481.5000 - val_loss: 4137957.7500\n",
      "Epoch 92/100\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 4083732.5000 - val_loss: 6213001.0000\n",
      "Epoch 93/100\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 3971257.0000 - val_loss: 3673465.5000\n",
      "Epoch 94/100\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 3943430.5000 - val_loss: 3921683.7500\n",
      "Epoch 95/100\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 3971378.2500 - val_loss: 3567086.2500\n",
      "Epoch 96/100\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 3798925.0000 - val_loss: 3496744.5000\n",
      "Epoch 97/100\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 3776126.2500 - val_loss: 3562081.2500\n",
      "Epoch 98/100\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 3704573.5000 - val_loss: 3439374.0000\n",
      "Epoch 99/100\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 3613106.7500 - val_loss: 3959337.0000\n",
      "Epoch 100/100\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 3724402.0000 - val_loss: 3472349.2500\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 84)                672       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 84)                7140      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 84)                7140      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 84)                7140      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 84)                7140      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 85        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29317 (114.52 KB)\n",
      "Trainable params: 29317 (114.52 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train,y_train,validation_data=(x_test,y_test),batch_size=128,epochs=100)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208/208 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "tahmin=model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.989933537492834"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(tahmin,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7629.1855],\n",
       "       [ 8697.338 ],\n",
       "       [10297.362 ],\n",
       "       ...,\n",
       "       [10098.811 ],\n",
       "       [ 9536.91  ],\n",
       "       [10315.992 ]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
